# GPU Support Guide

## Supported Hardware

Exsa-Engine supports **all major GPUs** through llama.cpp:

| GPU Type | Support | Status | Setup Required |
|----------|---------|--------|----------------|
| **Apple Silicon** (M1/M2/M3) | âœ… Metal | **Ready** | None (built-in) |
| **NVIDIA** (RTX, Tesla) | âœ… CUDA | Available | CUDA Toolkit |
| **AMD** (Radeon, Instinct) | âœ… ROCm | Available | ROCm SDK |
| **Intel Arc** | âœ… Vulkan | Experimental | Vulkan SDK |
| **CPU** (any) | âœ… Always | **Ready** | None |

---

## Quick Start

### Apple Silicon (M1/M2/M3) - Ready Now!

**No setup needed** - Metal support is built-in:

```bash
# .env
GPU_LAYERS=32  # Offload to GPU
```

**Performance**: 10-15x faster than CPU

---

## Enabling Other GPUs

### NVIDIA (CUDA)

**Requirements**:
- NVIDIA GPU (RTX 2060+, Tesla, etc.)
- [CUDA Toolkit 11.8+](https://developer.nvidia.com/cuda-downloads)

**Setup**:

1. **Install CUDA Toolkit**:
```bash
# Linux
sudo apt install nvidia-cuda-toolkit

# Windows
# Download from NVIDIA website
```

2. **Enable in Cargo.toml**:
```toml
llama-cpp-2 = { version = "0.1", features = ["cuda"] }
```

3. **Rebuild**:
```bash
cargo build --release
```

4. **Configure**:
```bash
# .env
GPU_LAYERS=40  # More layers for NVIDIA
```

**Performance**: 50-100 tokens/sec on RTX 4090

---

### AMD (ROCm)

**Requirements**:
- AMD GPU (RX 6000+, Instinct)
- [ROCm 5.0+](https://www.amd.com/en/graphics/servers-solutions-rocm)

**Setup**:

1. **Install ROCm**:
```bash
# Linux (Ubuntu/RHEL)
wget https://repo.radeon.com/rocm/apt/latest/install.sh
sudo bash install.sh
```

2. **Enable in Cargo.toml**:
```toml
llama-cpp-2 = { version = "0.1", features = ["rocm"] }
```

3. **Rebuild**:
```bash
cargo build --release
```

4. **Configure**:
```bash
# .env
GPU_LAYERS=35
```

**Performance**: 40-80 tokens/sec (varies by model)

---

### Vulkan (Cross-Platform)

**Requirements**:
- Any Vulkan-compatible GPU
- [Vulkan SDK](https://vulkan.lunarg.com/)

**Setup**:

1. **Install Vulkan SDK**:
```bash
# Linux
sudo apt install vulkan-tools libvulkan-dev

# macOS
brew install vulkan-headers vulkan-loader

# Windows
# Download from LunarG
```

2. **Enable in Cargo.toml**:
```toml
llama-cpp-2 = { version = "0.1", features = ["vulkan"] }
```

3. **Rebuild**:
```bash
cargo build --release
```

**Performance**: 30-70 tokens/sec (depends on GPU)

---

## Multi-GPU Support

### Enable All GPUs

```toml
llama-cpp-2 = { version = "0.1", features = ["cuda", "rocm", "vulkan"] }
```

**Auto-Detection**: Engine automatically uses the best available GPU

**Priority**:
1. CUDA (if NVIDIA detected)
2. ROCm (if AMD detected)
3. Metal (if Apple Silicon)
4. Vulkan (fallback)
5. CPU (always works)

---

## CPU-Only Mode

**No GPU? No problem!**

```bash
# .env
GPU_LAYERS=0  # CPU only
```

**Works on any system** - just slower (5-10 tokens/sec)

---

## Configuration Examples

### Optimal Settings by GPU

**NVIDIA RTX 4090**:
```bash
GPU_LAYERS=60        # Offload almost everything
CONTEXT_SIZE=4096    # Large context
```

**Apple M2 Max**:
```bash
GPU_LAYERS=32        # Sweet spot for unified memory
CONTEXT_SIZE=2048
```

**AMD RX 7900 XT**:
```bash
GPU_LAYERS=40
CONTEXT_SIZE=3072
```

**CPU Only (32 cores)**:
```bash
GPU_LAYERS=0
CONTEXT_SIZE=2048
```

---

## Performance Comparison

| Hardware | Speed (tokens/sec) | Best For |
|----------|-------------------|----------|
| NVIDIA RTX 4090 | 80-120 | Production servers |
| Apple M2 Ultra | 60-100 | Local development |
| AMD RX 7900 | 50-90 | Cost-effective GPU |
| Intel Arc A770 | 30-60 | Budget option |
| CPU (32 cores) | 5-15 | No GPU available |

---

## Troubleshooting

### CUDA Not Found

```bash
# Check CUDA installation
nvcc --version

# Set CUDA path
export CUDA_PATH=/usr/local/cuda
```

### ROCm Not Detected

```bash
# Verify ROCm
rocminfo

# Check device
clinfo | grep AMD
```

### Vulkan Issues

```bash
# Test Vulkan
vulkaninfo

# Install drivers
sudo apt install mesa-vulkan-drivers
```

---

## Benchmarking

**Test your GPU**:

```bash
# Run benchmark
./target/release/benchmark

# Check GPU utilization
# NVIDIA: nvidia-smi
# AMD: rocm-smi
# Apple: Activity Monitor > GPU
```

---

## Summary

âœ… **Apple Silicon**: Works out of the box  
âœ… **NVIDIA**: Requires CUDA toolkit  
âœ… **AMD**: Requires ROCm  
âœ… **Intel/Others**: Vulkan support  
âœ… **CPU**: Always available  

**The engine auto-detects and uses the best GPU available!** ðŸš€
